> #breast cancer data, creating a decision tree to predict diagnosis
> setwd("C:/Users/James Jaffray Duncan/Desktop/Code Examples/Resources")
> mydata<-read.csv("breast_cancer.csv")
> library(psych)
> library(ggplot2)
> library(caret)
> inTrain<-createDataPartition(y=mydata$diagnosis,p=0.7,list=FALSE)
> training1<-mydata[inTrain,][-1]
> testing1<-mydata[-inTrain,][-1]
> dim(training1);dim(testing1)
[1] 399  31
[1] 170  31
> table(training1$diagnosis)

  B   M 
250 149 
> table(testing1$diagnosis)

  B   M 
107  63 
> library(C50)
> model<-C5.0(training1[-1],training1$diagnosis)
> summary(model)

Call:
C5.0.default(x = training1[-1], y = training1$diagnosis)


C5.0 [Release 2.07 GPL Edition]  	Sat Mar 05 17:35:45 2016
-------------------------------

Class specified by attribute `outcome'

Read 399 cases (31 attributes) from undefined.data

Decision tree:

perimeter_worst > 112.5:
:...concavity_mean > 0.06195: M (119)
:   concavity_mean <= 0.06195:
:   :...texture_mean <= 19.51: B (5)
:       texture_mean > 19.51: M (8)
perimeter_worst <= 112.5:
:...compactness_worst > 0.3949:
    :...smoothness_mean <= 0.1012: B (5)
    :   smoothness_mean > 0.1012: M (12)
    compactness_worst <= 0.3949:
    :...perimeter_worst <= 101.7: B (218/1)
        perimeter_worst > 101.7:
        :...texture_mean <= 20.68: B (20/1)
            texture_mean > 20.68:
            :...smoothness_se <= 0.005356: B (5/1)
                smoothness_se > 0.005356: M (7)


Evaluation on training data (399 cases):

	    Decision Tree   
	  ----------------  
	  Size      Errors  

	     9    3( 0.8%)   <<


	   (a)   (b)    <-classified as
	  ----  ----
	   250          (a): class B
	     3   146    (b): class M


	Attribute usage:

	100.00%	perimeter_worst
	 66.92%	compactness_worst
	 33.08%	concavity_mean
	 11.28%	texture_mean
	  4.26%	smoothness_mean
	  3.01%	smoothness_se


Time: 0.0 secs

> predicted<-predict(model,testing1)
> table(predicted)
predicted
  B   M 
105  65 
> confusionMatrix(predicted,testing1$diagnosis)
Confusion Matrix and Statistics

          Reference
Prediction  B  M
         B 98  7
         M  9 56
                                          
               Accuracy : 0.9059          
                 95% CI : (0.8517, 0.9452)
    No Information Rate : 0.6294          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.7996          
 Mcnemar's Test P-Value : 0.8026          
                                          
            Sensitivity : 0.9159          
            Specificity : 0.8889          
         Pos Pred Value : 0.9333          
         Neg Pred Value : 0.8615          
             Prevalence : 0.6294          
         Detection Rate : 0.5765          
   Detection Prevalence : 0.6176          
      Balanced Accuracy : 0.9024          
                                          
       'Positive' Class : B               
                                          
> names(mydata)
 [1] "id"                "diagnosis"         "radius_mean"       "texture_mean"     
 [5] "perimeter_mean"    "area_mean"         "smoothness_mean"   "compactness_mean" 
 [9] "concavity_mean"    "points_mean"       "symmetry_mean"     "dimension_mean"   
[13] "radius_se"         "texture_se"        "perimeter_se"      "area_se"          
[17] "smoothness_se"     "compactness_se"    "concavity_se"      "points_se"        
[21] "symmetry_se"       "dimension_se"      "radius_worst"      "texture_worst"    
[25] "perimeter_worst"   "area_worst"        "smoothness_worst"  "compactness_worst"
[29] "concavity_worst"   "points_worst"      "symmetry_worst"    "dimension_worst"  
> #now lets try a smaller decision tree using only the top 4 attributes used (from the model summary)
> submydata<-mydata[,c(2,25,28,4,9)]
> summary(submydata)
 diagnosis perimeter_worst  compactness_worst  texture_mean   concavity_mean   
 B:357     Min.   : 50.41   Min.   :0.02729   Min.   : 9.71   Min.   :0.00000  
 M:212     1st Qu.: 84.11   1st Qu.:0.14720   1st Qu.:16.17   1st Qu.:0.02956  
           Median : 97.66   Median :0.21190   Median :18.84   Median :0.06154  
           Mean   :107.26   Mean   :0.25427   Mean   :19.29   Mean   :0.08880  
           3rd Qu.:125.40   3rd Qu.:0.33910   3rd Qu.:21.80   3rd Qu.:0.13070  
           Max.   :251.20   Max.   :1.05800   Max.   :39.28   Max.   :0.42680  
> inTrain<-createDataPartition(y=submydata$diagnosis,p=0.7,list=FALSE)
> training2<-submydata[inTrain,]
> testing2<-submydata[-inTrain,]
> model<-C5.0(training2[-1],training2$diagnosis)
> summary(model)

Call:
C5.0.default(x = training2[-1], y = training2$diagnosis)


C5.0 [Release 2.07 GPL Edition]  	Sat Mar 05 17:37:44 2016
-------------------------------

Class specified by attribute `outcome'

Read 399 cases (5 attributes) from undefined.data

Decision tree:

perimeter_worst > 117.2: M (118/2)
perimeter_worst <= 117.2:
:...compactness_worst <= 0.3663:
    :...perimeter_worst <= 101.7: B (215/3)
    :   perimeter_worst > 101.7:
    :   :...texture_mean <= 17: B (18)
    :       texture_mean > 17:
    :       :...concavity_mean <= 0.1112: B (17/7)
    :           concavity_mean > 0.1112: M (4)
    compactness_worst > 0.3663:
    :...texture_mean > 20.2: M (14)
        texture_mean <= 20.2:
        :...compactness_worst <= 0.4082: B (5)
            compactness_worst > 0.4082:
            :...perimeter_worst <= 106.4: M (6/1)
                perimeter_worst > 106.4: B (2)


Evaluation on training data (399 cases):

	    Decision Tree   
	  ----------------  
	  Size      Errors  

	     9   13( 3.3%)   <<


	   (a)   (b)    <-classified as
	  ----  ----
	   247     3    (a): class B
	    10   139    (b): class M


	Attribute usage:

	100.00%	perimeter_worst
	 70.43%	compactness_worst
	 16.54%	texture_mean
	  5.26%	concavity_mean


Time: 0.0 secs

> predicted<-predict(model,testing2)
> confusionMatrix(predicted,testing2$diagnosis)
Confusion Matrix and Statistics

          Reference
Prediction   B   M
         B 101   7
         M   6  56
                                          
               Accuracy : 0.9235          
                 95% CI : (0.8728, 0.9587)
    No Information Rate : 0.6294          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.8355          
 Mcnemar's Test P-Value : 1               
                                          
            Sensitivity : 0.9439          
            Specificity : 0.8889          
         Pos Pred Value : 0.9352          
         Neg Pred Value : 0.9032          
             Prevalence : 0.6294          
         Detection Rate : 0.5941          
   Detection Prevalence : 0.6353          
      Balanced Accuracy : 0.9164          
                                          
       'Positive' Class : B               
                                          
> #lets try to build a decision tree with the library(caret), library(tree), and library(ISLR)
> library(tree);library(caret);library(ISLR)
> #we want to minimize deviance
> #using more predictors does not necessarily make the tree fit the data better
> #excessive predictors cause an increase in variance, but reduce bias
> #method to find the best tree is to start with all predictors then prune the tree
> #we want the tree with the lowest error rate
> tree1<-tree(diagnosis~.,training1)
> plot(tree1);text(tree1,pretty=0)
> summary(tree1)

Classification tree:
tree(formula = diagnosis ~ ., data = training1)
Variables actually used in tree construction:
[1] "radius_worst"      "points_worst"      "smoothness_se"     "compactness_worst"
[5] "texture_worst"     "concavity_worst"  
Number of terminal nodes:  8 
Residual mean deviance:  0.08184 = 32 / 391 
Misclassification error rate: 0.01754 = 7 / 399 
> cv.tree1<-cv.tree(tree1)
> #performs cross validation, determines if pruning the tree will improve performance
> plot(cv.tree1)
> head(cv.tree1)
$size
[1] 8 7 6 5 4 3 2 1

$dev
[1] 227.2821 229.4706 223.9335 216.0897 210.8700 179.4983 238.9315 528.7767

$k
[1]       -Inf   7.885134   8.709027  13.936504  19.783585  26.230679  83.026119
[8] 335.715701

$method
[1] "deviance"

> #appears that deviance is lowest when the tree size is 3
> #for a tree of size 3
> prune.tree1<-prune.tree(tree1,best=3)
> plot(prune.tree1);text(prune.tree1,pretty=0)
> #now lets use the pruned model to make predictions on the testing1 data set
> tree.pred<-predict(prune.tree1,testing1,type='class')
> confusionMatrix(tree.pred,testing1$diagnosis)
Confusion Matrix and Statistics

          Reference
Prediction  B  M
         B 96  4
         M 11 59
                                          
               Accuracy : 0.9118          
                 95% CI : (0.8586, 0.9498)
    No Information Rate : 0.6294          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.8151          
 Mcnemar's Test P-Value : 0.1213          
                                          
            Sensitivity : 0.8972          
            Specificity : 0.9365          
         Pos Pred Value : 0.9600          
         Neg Pred Value : 0.8429          
             Prevalence : 0.6294          
         Detection Rate : 0.5647          
   Detection Prevalence : 0.5882          
      Balanced Accuracy : 0.9169          
                                          
       'Positive' Class : B               
                                          
> #91.18% accuracy, with Kappa of 0.8151, and balanced accuracy of 91.69%
> #now what happens when we choose a tree size of 4 (which also had low deviance)
> prune.tree2<-prune.tree(tree1,best=4)
> plot(prune.tree2);text(prune.tree2,pretty=0)
> #now lets use the pruned model to make predictions on the testing1 data set
> tree.pred2<-predict(prune.tree2,testing1,type='class')
> confusionMatrix(tree.pred2,testing1$diagnosis)
Confusion Matrix and Statistics

          Reference
Prediction  B  M
         B 97  6
         M 10 57
                                          
               Accuracy : 0.9059          
                 95% CI : (0.8517, 0.9452)
    No Information Rate : 0.6294          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.8008          
 Mcnemar's Test P-Value : 0.4533          
                                          
            Sensitivity : 0.9065          
            Specificity : 0.9048          
         Pos Pred Value : 0.9417          
         Neg Pred Value : 0.8507          
             Prevalence : 0.6294          
         Detection Rate : 0.5706          
   Detection Prevalence : 0.6059          
      Balanced Accuracy : 0.9057          
                                          
       'Positive' Class : B               
                                          
> #90.59% accuracy, with Kappa of 0.8008, and balanced accuracy of 90.57%
> #note that while the deviance is low, it is not as good a tree as when best=3
> #the model with 3 nodes gives us the best balanced accuracy and the highest Kappa
> #thus it is likely the best model to use
